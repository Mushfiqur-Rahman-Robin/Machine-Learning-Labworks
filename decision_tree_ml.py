# -*- coding: utf-8 -*-
"""decision_tree_ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lnBgf2_B6nZ7YCQ5dVLjiYO65dqwFwRY
"""

import numpy as np 
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

my_data = pd.read_csv("/content/depression_ml.csv",header=0, delimiter=",")
my_data.head()

my_data = my_data.drop(['Timestamp'], axis = 1)
my_data

from sklearn import preprocessing
import numpy as np
oh = preprocessing.OneHotEncoder()
le = preprocessing.LabelEncoder()

selected_col = list(my_data.columns)
selected_col

to_delete = [1,2,4,8,19]

selected_col = np.delete(selected_col, to_delete).tolist()
selected_col

my_data.dtypes

my_data.isnull().sum()

my_data.duplicated().sum()

my_data.shape

import seaborn as sns

corr = my_data.corr()
sns.heatmap(corr,annot=True,cmap='Reds')

from sklearn import preprocessing
oh = preprocessing.OneHotEncoder()
le = preprocessing.LabelEncoder()

my_data[selected_col] = my_data[selected_col].apply(le.fit_transform)
my_data

X = my_data.iloc[: , [0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]]
X.head()

Y = my_data.iloc[:, 1]
Y.head()

from sklearn.model_selection import train_test_split

X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, Y, test_size = 0.33, random_state= 42)

X_trainset.shape, X_testset.shape, y_trainset.shape, y_testset.shape

depressionTree = DecisionTreeClassifier(criterion="entropy", max_depth = 10)
depressionTree

depressionTree.fit(X_trainset,y_trainset)

predTree = depressionTree.predict(X_testset)

print (predTree [0:5])
print (y_testset [0:5])

compare_scores = pd.DataFrame({'Actual Score': y_testset, 'Predicted Score': predTree})
compare_scores.head()

from sklearn import metrics
import matplotlib.pyplot as plt
print("DecisionTrees's Accuracy: ", metrics.accuracy_score(y_testset, predTree))

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
#k-fold CV using Sklearn
scores = cross_val_score(depressionTree, X_trainset, y_trainset,  cv= 10)
scores

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
#k-fold CV using Sklearn
scores = cross_val_score(depressionTree, X_testset, y_testset, cv= 10)
scores

from sklearn.metrics import classification_report

print(metrics.accuracy_score(y_testset, predTree))
print(classification_report(y_testset, predTree))

feature_cols = list(my_data.columns)
feature_cols.pop(1)
feature_cols

from sklearn.externals.six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
from sklearn import tree

dot_data = StringIO()
export_graphviz(depressionTree, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True, feature_names = feature_cols)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('decisiontree.png')
Image(graph.create_png())

criteria = [2, 40,	0,	19.60,	1,	0,	0,	1,	1,	0,	0,	0,	1,	2,	1,	2,	0,	1,	3.0]
feeling = depressionTree.predict([criteria])
print("Score = {}".format(feeling[0]))

